{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K8sM32M9Ae7"
      },
      "source": [
        "## Preparing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW1TKXBb80IM"
      },
      "source": [
        "### 1) Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onpa6MgF0VpQ",
        "outputId": "83ad89a8-3a3f-4ce1-adf5-a2d8b65239b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting underthesea\n",
            "  Downloading underthesea-1.3.4-py3-none-any.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.1.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.13)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from underthesea) (2.23.0)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 32.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from underthesea) (4.62.3)\n",
            "Collecting underthesea-core==0.0.4_alpha.10\n",
            "  Downloading underthesea_core-0.0.4_alpha.10-cp37-cp37m-manylinux2010_x86_64.whl (581 kB)\n",
            "\u001b[K     |████████████████████████████████| 581 kB 42.1 MB/s \n",
            "\u001b[?25hCollecting python-crfsuite>=0.9.6\n",
            "  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 42.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->underthesea) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (1.19.5)\n",
            "Installing collected packages: unidecode, underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.7 underthesea-1.3.4 underthesea-core-0.0.4a10 unidecode-1.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install underthesea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RzNh9zR1x12s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
        "import pandas as pd\n",
        "import underthesea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83aRhJ8489j3"
      },
      "source": [
        "### 2) Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUcVxgCRxcZ7",
        "outputId": "001a4ab9-eec6-42af-d946-fbaae3a72473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-13 03:03:49--  http://www.manythings.org/anki/vie-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 172.67.186.54, 104.21.92.44, 2606:4700:3030::6815:5c2c, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|172.67.186.54|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 317038 (310K) [application/zip]\n",
            "Saving to: ‘vie-eng.zip’\n",
            "\n",
            "vie-eng.zip         100%[===================>] 309.61K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-01-13 03:03:49 (5.01 MB/s) - ‘vie-eng.zip’ saved [317038/317038]\n",
            "\n",
            "Archive:  vie-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: vie.txt                 \n"
          ]
        }
      ],
      "source": [
        "!wget http://www.manythings.org/anki/vie-eng.zip -O vie-eng.zip\n",
        "!unzip vie-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5hZjg0MKxmGL",
        "outputId": "66dca55e-7127-4e33-81a8-55760dad0540"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e98544f7-5479-441a-ae9e-1e0c6652953b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>vie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Chạy !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Help!</td>\n",
              "      <td>Giúp tôi với !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go on.</td>\n",
              "      <td>Tiếp_tục đi .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>Chào bạn .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hurry!</td>\n",
              "      <td>Nhanh lên nào !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e98544f7-5479-441a-ae9e-1e0c6652953b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e98544f7-5479-441a-ae9e-1e0c6652953b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e98544f7-5479-441a-ae9e-1e0c6652953b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      eng              vie\n",
              "0    Run!           Chạy !\n",
              "1   Help!   Giúp tôi với !\n",
              "2  Go on.    Tiếp_tục đi .\n",
              "3  Hello!       Chào bạn .\n",
              "4  Hurry!  Nhanh lên nào !"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "lines = pd.read_table('vie.txt', names=['eng', 'vie'])\n",
        "lines.reset_index(inplace=True)\n",
        "lines.rename( columns={ 'index' : 'eng' , 'eng' : 'vie' , 'vie' : 'c' }, inplace=True)\n",
        "lines.drop('c', axis=1, inplace=True)\n",
        "lines.vie = lines.vie.map(lambda x: underthesea.word_tokenize(x, format='text'))\n",
        "lines.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ass3El-R-SdF"
      },
      "source": [
        "### 3) Preparing input data for the Encoder ( `encoder_input_data` )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8uOHQtt17rC",
        "outputId": "5bf34017-c8ac-4f54-e503-b9b5912a6227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vietnamese max length is 32\n",
            "Encoder input data shape -> (7966, 32)\n",
            "Number of Vietnamese tokens = 3789\n"
          ]
        }
      ],
      "source": [
        "eng_lines = list(lines.eng)\n",
        "\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(eng_lines)\n",
        "tokenized_eng_lines = tokenizer.texts_to_sequences(eng_lines)\n",
        "\n",
        "max_input_length = len(max(tokenized_eng_lines, key=len))\n",
        "print( 'Vietnamese max length is {}'.format(max_input_length))\n",
        "\n",
        "padded_eng_lines = preprocessing.sequence.pad_sequences(tokenized_eng_lines, maxlen=max_input_length, padding='post')\n",
        "encoder_input_data = np.array(padded_eng_lines)\n",
        "print( 'Encoder input data shape -> {}'.format(encoder_input_data.shape))\n",
        "\n",
        "eng_word_dict = tokenizer.word_index\n",
        "num_eng_tokens = len( eng_word_dict ) + 1\n",
        "print( 'Number of Vietnamese tokens = {}'.format(num_eng_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OPGQG2U-Zz-"
      },
      "source": [
        "### 4) Preparing input data for the Decoder ( `decoder_input_data` )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXeXkn4W48iF",
        "outputId": "2029f0f7-a2c4-453e-8903-e351cbf8a405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vietnamese max length is 43\n",
            "Decoder input data shape -> (7966, 43)\n",
            "Number of Vietnamese tokens = 2383\n"
          ]
        }
      ],
      "source": [
        "vie_lines = list(lines.vie.map(lambda x: 'START ' + x + ' END'))\n",
        "\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(vie_lines)\n",
        "tokenized_vie_lines = tokenizer.texts_to_sequences(vie_lines)\n",
        "\n",
        "max_output_length = len(max(tokenized_vie_lines, key=len))\n",
        "print( 'Vietnamese max length is {}'.format(max_output_length))\n",
        "\n",
        "padded_vie_lines = preprocessing.sequence.pad_sequences(tokenized_vie_lines, maxlen=max_output_length, padding='post')\n",
        "decoder_input_data = np.array(padded_vie_lines)\n",
        "print( 'Decoder input data shape -> {}'.format(decoder_input_data.shape))\n",
        "\n",
        "vie_word_dict = tokenizer.word_index\n",
        "num_vie_tokens = len(vie_word_dict) + 1\n",
        "print( 'Number of Vietnamese tokens = {}'.format(num_vie_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOHumtnmBrK2"
      },
      "source": [
        "### 5) Preparing target data for the Decoder ( decoder_target_data )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jvVso7uCAbF"
      },
      "source": [
        "For example :\n",
        "\n",
        "```\n",
        " [ '<start>' , 'hello' , 'world' , '<end>' ]\n",
        "\n",
        "```\n",
        "\n",
        "wil become \n",
        "\n",
        "```\n",
        " [ 'hello' , 'world' , '<end>' ]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPw4Vubl5FRc",
        "outputId": "cefdefa0-24ef-483c-acba-ba0c8f82c91d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder target data shape -> (7966, 43, 2383)\n"
          ]
        }
      ],
      "source": [
        "decoder_target_data = list(map(lambda token_seq: token_seq[1: ], tokenized_vie_lines))\n",
        "\n",
        "padded_vie_lines = preprocessing.sequence.pad_sequences(decoder_target_data , maxlen=max_output_length, padding='post')\n",
        "onehot_vie_lines = utils.to_categorical(padded_vie_lines , num_vie_tokens)\n",
        "decoder_target_data = np.array(onehot_vie_lines)\n",
        "print( 'Decoder target data shape -> {}'.format( decoder_target_data.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqqdqpC5DQJf"
      },
      "source": [
        "## Defining and Training the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbN8fkdLDRTg"
      },
      "source": [
        "### 1) Defining the Encoder-Decoder model\n",
        "The model will have Embedding, LSTM and Dense layers. The basic configuration is as follows.\n",
        "\n",
        "\n",
        "*   2 Input Layers : One for `encoder_input_data` and another for `decoder_input_data`.\n",
        "*   Embedding layer : For converting token vectors to fix sized dense vectors. **( Note :  Don't forget the `mask_zero=True` argument here )**\n",
        "*   LSTM layer : Provide access to Long-Short Term cells.\n",
        "\n",
        "Working : \n",
        "\n",
        "1.   The `encoder_input_data` comes in the Embedding layer (  `encoder_embedding` ). \n",
        "2.   The output of the Embedding layer goes to the LSTM cell which produces 2 state vectors ( `h` and `c` which are `encoder_states` )\n",
        "3.   These states are set in the LSTM cell of the decoder.\n",
        "4.   The decoder_input_data comes in through the Embedding layer.\n",
        "5.   The Embeddings goes in LSTM cell ( which had the states ) to produce sequences.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eNeYeS2PFbEL"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo4TmWY7ChL1",
        "outputId": "fd5515d1-31e3-4444-8a15-28f1d0236a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 256)    969984      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 256)    610048      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 128),        197120      ['embedding[0][0]']              \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 128),  197120      ['embedding_1[0][0]',            \n",
            "                                 (None, 128),                     'lstm[0][1]',                   \n",
            "                                 (None, 128)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 2383)   307407      ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,281,679\n",
            "Trainable params: 2,281,679\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "encoder_inputs = layers.Input(shape=(None, ))\n",
        "encoder_embedding = layers.Embedding(num_eng_tokens, 256, mask_zero=True)(encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = layers.LSTM(128, return_state=True)(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = layers.Input(shape=(None, ))\n",
        "decoder_embedding = layers.Embedding(num_vie_tokens, 256, mask_zero=True)(decoder_inputs)\n",
        "decoder_lstm = layers.LSTM(128, return_state=True, return_sequences=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_dense = layers.Dense(num_vie_tokens, activation='softmax')\n",
        "output = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy')\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLGjMpL8F2y_"
      },
      "source": [
        "### 2) Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LPYsgXFCyBI",
        "outputId": "dcfe482f-872f-4b64-af09-783680a669d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "498/498 [==============================] - 26s 28ms/step - loss: 1.2172\n",
            "Epoch 2/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 1.0493\n",
            "Epoch 3/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.9555\n",
            "Epoch 4/50\n",
            "498/498 [==============================] - 14s 28ms/step - loss: 0.8823\n",
            "Epoch 5/50\n",
            "498/498 [==============================] - 14s 28ms/step - loss: 0.8166\n",
            "Epoch 6/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.7561\n",
            "Epoch 7/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.6995\n",
            "Epoch 8/50\n",
            "498/498 [==============================] - 14s 28ms/step - loss: 0.6468\n",
            "Epoch 9/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.5982\n",
            "Epoch 10/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.5526\n",
            "Epoch 11/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.5098\n",
            "Epoch 12/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.4703\n",
            "Epoch 13/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.4339\n",
            "Epoch 14/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.3998\n",
            "Epoch 15/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.3691\n",
            "Epoch 16/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.3409\n",
            "Epoch 17/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.3147\n",
            "Epoch 18/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.2902\n",
            "Epoch 19/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.2676\n",
            "Epoch 20/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.2482\n",
            "Epoch 21/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.2295\n",
            "Epoch 22/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.2121\n",
            "Epoch 23/50\n",
            "498/498 [==============================] - 14s 28ms/step - loss: 0.1971\n",
            "Epoch 24/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.1823\n",
            "Epoch 25/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.1690\n",
            "Epoch 26/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.1572\n",
            "Epoch 27/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.1456\n",
            "Epoch 28/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.1354\n",
            "Epoch 29/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.1254\n",
            "Epoch 30/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.1173\n",
            "Epoch 31/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.1088\n",
            "Epoch 32/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.1015\n",
            "Epoch 33/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.0952\n",
            "Epoch 34/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.0891\n",
            "Epoch 35/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.0829\n",
            "Epoch 36/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.0774\n",
            "Epoch 37/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.0725\n",
            "Epoch 38/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.0694\n",
            "Epoch 39/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.0647\n",
            "Epoch 40/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.0605\n",
            "Epoch 41/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.0574\n",
            "Epoch 42/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.0548\n",
            "Epoch 43/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.0520\n",
            "Epoch 44/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.0491\n",
            "Epoch 45/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.0474\n",
            "Epoch 46/50\n",
            "498/498 [==============================] - 14s 27ms/step - loss: 0.0447\n",
            "Epoch 47/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.0419\n",
            "Epoch 48/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.0411\n",
            "Epoch 49/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.0392\n",
            "Epoch 50/50\n",
            "498/498 [==============================] - 13s 27ms/step - loss: 0.0376\n"
          ]
        }
      ],
      "source": [
        "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=16, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "_1KuJ34vIlyi",
        "outputId": "ca8ce1e4-6866-4005-f900-b59ca99ea201"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f356ffab250>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhU5Z328e+vq6v3faFZupsdZZG1bY0KYhRFjUteHZVoEpMgk6gZjb6ZMZPFxDiTmeSdaGLMKDFEjaNAohEcNcSoCRJBaTbZFJC12bppmgZ6X573jyq0g0AX3dV9uqruz3X1VXWWOud3Lsu7Hp5zznPMOYeIiES+OK8LEBGR8FCgi4hECQW6iEiUUKCLiEQJBbqISJSI92rHeXl5btCgQV7tXkQkIq1YseKAcy7/RMs8C/RBgwZRVlbm1e5FRCKSme042TJ1uYiIRAkFuohIlFCgi4hECc/60EVEwqG5uZny8nIaGhq8LiWskpKSKCwsxO/3h/wZBbqIRLTy8nLS09MZNGgQZuZ1OWHhnKOqqory8nIGDx4c8ufU5SIiEa2hoYHc3NyoCXMAMyM3N/e0/9WhQBeRiBdNYX5MZ44p4gL9g31H+LeXN1Df1Op1KSIivUqHgW5mc8yswszWnWT5zWb2npmtNbO3zWxc+Mv8WHl1Hb96axvvlR/qzt2IiIQsLS3N6xKA0FroTwLTT7F8G3Chc+4s4IfA7DDUdVITirMBWLVLgS4i0l6Hge6cWwwcPMXyt51z1cHJZUBhmGo7oZzUBAblprByR3XHK4uI9CDnHN/85jcZM2YMZ511FvPmzQNg7969TJkyhfHjxzNmzBjeeustWltbufXWWz9a96GHHury/sN92eJXgFdPttDMZgGzAIqLizu9k4nF2by15QDOuag8GSIinfODl9azYc/hsG5zVP8M7r9qdEjrvvDCC6xevZo1a9Zw4MABzj77bKZMmcKzzz7LZZddxre//W1aW1upq6tj9erV7N69m3XrAr3Zhw51vdchbCdFzewiAoH+Lydbxzk32zlX4pwryc8/4WBhIZlQnEXlkUbKq+s7vQ0RkXBbsmQJM2bMwOfzUVBQwIUXXsjy5cs5++yz+c1vfsP3v/991q5dS3p6OkOGDGHr1q18/etf549//CMZGRld3n9YWuhmNhZ4ArjcOVcVjm2eSvt+9KKclO7enYhEiFBb0j1typQpLF68mJdffplbb72Ve+65hy984QusWbOGRYsW8dhjjzF//nzmzJnTpf10uYVuZsXAC8DnnXOburq9UJzZN51kv0/96CLSq0yePJl58+bR2tpKZWUlixcvprS0lB07dlBQUMBtt93GzJkzWblyJQcOHKCtrY3rrruOBx98kJUrV3Z5/x220M3sOWAqkGdm5cD9gB/AOfcY8D0gF/hlsD+7xTlX0uXKTiHeF8fYwkxd6SIivcpnP/tZli5dyrhx4zAzfvzjH9O3b1+eeuopfvKTn+D3+0lLS+Ppp59m9+7dfOlLX6KtrQ2AH/3oR13evznnuryRzigpKXFdecDFf7z6Pr9espW137+MJL8vjJWJSCTZuHEjI0eO9LqMbnGiYzOzFSdrNEfcnaLHTCzOornVsX5PjdeliIj0ChEb6MdOjK7coW4XERGI4EDPT0+kKCeZVbt0YlQk1nnVddydOnNMERvoABOKstVCF4lxSUlJVFVVRVWoHxsPPSkp6bQ+F9EPuJhYnMXCNXvYW1NPv8xkr8sREQ8UFhZSXl5OZWWl16WE1bEnFp2OiA709v3oV45VoIvEIr/ff1pP9YlmEd3lMrJfBonxcazaqX50EZGIDvSE+DjOGpDJSgW6iEhkBzrAxIHZrNtzmMYWPcFIRGJb5Ad6cRZNLW1hHzJTRCTSRHygfzTy4k5dvigisS3iA70gI4kBWcnqRxeRmBfxgQ4wvjhLLXQRiXlREegTi7PZfaieisMNXpciIuKZqAj0CcVZAKxUK11EYlhUBPro/hkk+HSDkYjEtqgI9MR4H6MHZKgfXURiWlQEOgT60d/bfYjm1javSxER8UTUBPqE4iwamtt4f+8Rr0sREfFE1AR6ycAcAP7yQYXHlYiIeCNqAr1vZhLnD8tlXtku2tqiZ6B7EZFQRU2gA9x0djHl1fUs2XLA61JERHpcVAX6paMLyE7xM3f5Tq9LERHpcVEV6InxPq6bWMif1u+n8kij1+WIiPSoDgPdzOaYWYWZrTvJcjOzn5vZFjN7z8wmhr/M0N1UWkRLm+P5leVeliEi0uNCaaE/CUw/xfLLgeHBv1nAf3e9rM4b1ied0kE5zFu+K6qeAi4i0pEOA905txg4eIpVrgGedgHLgCwz6xeuAjvjptIith2oZdnWU5UtIhJdwtGHPgDY1W66PDjPM1ec1Y+MpHidHBWRmNKjJ0XNbJaZlZlZWWVlZbftJ8nv47MTBvDq2n1U1zZ1235ERHqTcAT6bqCo3XRhcN4nOOdmO+dKnHMl+fn5Ydj1yc04p5im1jZeWHXCUkREok44An0h8IXg1S7nAjXOub1h2G6XnNk3g/FFWcx9d6dOjopITAjlssXngKXAGWZWbmZfMbOvmtlXg6u8AmwFtgC/Am7vtmpP04zSIjZXHGXFDo2TLiLRL76jFZxzMzpY7oA7wlZRGH1mbH8eeGkDz727i5JBOV6XIyLSraLqTtHjpSbGc/X4Aby8dg819c1elyMi0q2iOtABPldaTENzGwtW6+SoiES3qA/0swozGVeUxezFW2lq0dOMRCR6RX2gA9x98XDKq+s1vouIRLWYCPSpZ+QzviiLX7yxRa10EYlaMRHoZsY3po1g96F65pft6vgDIiIRKCYCHWDK8DwmDczm0Te30NjS6nU5IiJhFzOBbmZ845IR7K1pYN5ytdJFJPrETKADnD8sl9JBOTz65hYamtVKF5HoElOBbmbcPW04+w838ty7GlpXRKJLTAU6wHlD8zh3SA6//MuHaqWLSFSJuUAH+MYlI6g80sgzy3Z4XYqISNjEZKCfMySX84bm8thfP6SuqcXrckREwiImAx3gG9NGcOBok1rpIhI1YjbQzx6Uw+ThefzyLx9SU6eRGEUk8sVsoAN86/KR1NQ388gbm70uRUSky2I60Ef1z+CGSUU8tXQ72w/Uel2OiEiXxHSgA9x76Qj8vjh+9OpGr0sREemSmA/0PhlJ3D51KIvW72fZ1iqvyxER6bSYD3SAmZOH0D8ziQdf3kBbm/O6HBGRTlGgA0l+H/9y+Zms232YF1bpUXUiEpkU6EFXje3PuKIsfrLofd1sJCIRSYEeFBdnfPfKkew/3Mjjf93qdTkiIqdNgd5OyaAcrhzbj8cXf8i+mgavyxEROS0K9OPcN/1M2trgx4ve97oUEZHTElKgm9l0M/vAzLaY2X0nWF5sZm+a2Soze8/Mrgh/qT2jKCeFL18wmBdW7mbFjoNelyMiErIOA93MfMCjwOXAKGCGmY06brXvAPOdcxOAm4BfhrvQnvT1Tw+jX2YS3/7DOlpa27wuR0QkJKG00EuBLc65rc65JmAucM1x6zggI/g+E9gTvhJ7XmpiPPdfNYr39x3hybe3e12OiEhIQgn0AUD7pyqXB+e1933gFjMrB14Bvn6iDZnZLDMrM7OyysrKTpTbcy4b3ZeLzsjnodc2sbem3utyREQ6FK6TojOAJ51zhcAVwG/N7BPbds7Nds6VOOdK8vPzw7Tr7mFm/ODqMbS0OR54aYPX5YiIdCiUQN8NFLWbLgzOa+8rwHwA59xSIAnIC0eBXirOTeGfLh7Oq+v28eYHFV6XIyJySqEE+nJguJkNNrMEAic9Fx63zk7gYgAzG0kg0Ht3n0qIbps8hKH5qdy/YL0eKi0ivVqHge6cawHuBBYBGwlczbLezB4ws6uDq90L3GZma4DngFudc1ExylVCfBw/vHYMOw/W8eibW7wuR0TkpOJDWck59wqBk53t532v3fsNwPnhLa33OG9oHp+dMIDH/voh104YwND8NK9LEhH5BN0pGqJ/vWIkyX4f331xHVHyjw8RiTIK9BDlpyfyzeln8vaHVTy/UkPsikjvo0A/DTeXFlMyMJsHXlpPxWEN3iUivYsC/TTExRn/ef1YGlra+O4Cdb2ISO+iQD9NQ/PTuGfaCBat388ra/d5XY6IyEcU6J0w84LBjC3M5HsL1nGwtsnrckREAAV6p8T74vjx9WM53NDMD15a73U5IiKAAr3TzuybwR0XDWPB6j38ecN+r8sREVGgd8XtU4dxZt90vv3iWmrqm70uR0RinAK9CxLiA10vlUca+feXN3pdjojEOAV6F40tzGLWlKHMK9vF4k1RMR6ZiEQoBXoY3H3JcIb1SeObv19Dta56ERGPKNDDIMnv4+Ebx3Owtol//cNa3XAkIp5QoIfJmAGZ3DPtDF5dt09jvYiIJxToYTRryhBKB+dw/4J17Kyq87ocEYkxCvQw8sUZP71hHHFm3DN/NS2tbV6XJCIxRIEeZoXZKfzw2jGU7ajmsb9+6HU5IhJDFOjd4Jrx/blqXH8e/vNm1uw65HU5IhIjFOjdwMx48Jox5Kcn8o15q6lravG6JBGJAQr0bpKZ4ue/bhjHtqpaHnhpg9fliEgMUKB3o/OG5vHVC4cyd/kuXlhZ7nU5IhLlFOjd7N5pIzhncA7f/sM6Nu0/4nU5IhLFFOjdLN4XxyMzJpCaGM/XnllBbaP600WkeyjQe0CfjCR+PmM82w7U8q0XNDSAiHQPBXoPOW9oHvdMG8HCNXt45p2dXpcjIlEopEA3s+lm9oGZbTGz+06yzg1mtsHM1pvZs+EtMzrcPnUYU8/I54cvbeC9cl2fLiLh1WGgm5kPeBS4HBgFzDCzUcetMxz4FnC+c240cHc31Brx4uKMh24YT15aArf/z0pq6vSUIxEJn1Ba6KXAFufcVudcEzAXuOa4dW4DHnXOVQM45yrCW2b0yE5N4Bc3T2T/4Qbumb+atjb1p4tIeIQS6AOAXe2my4Pz2hsBjDCzv5nZMjObfqINmdksMyszs7LKyth9us/E4my+c+UoXn+/gof/vMnrckQkSoTrpGg8MByYCswAfmVmWcev5Jyb7Zwrcc6V5Ofnh2nXkekLnxrIDSWF/PyNLbyydq/X5YhIFAgl0HcDRe2mC4Pz2isHFjrnmp1z24BNBAJeTsLM+OG1Y5hQnMW989ewce9hr0sSkQgXSqAvB4ab2WAzSwBuAhYet86LBFrnmFkegS6YrWGsMyolxvt4/JZJZCTHc9vTZRzU80hFpAs6DHTnXAtwJ7AI2AjMd86tN7MHzOzq4GqLgCoz2wC8CXzTOVfVXUVHkz4ZSTz++RIqjjRyx/+spFkPxRCRTjKv7losKSlxZWVlnuy7N3p+RTn3/m4Nt543iO9fPdrrckSklzKzFc65khMti+/pYuTErptUyIa9h/n1km2M6pfBDWcXdfwhEZF2dOt/L/Kty8/kgmF5fOfFdbyzVT1WInJ6FOi9SLwvjkc/N5GinGRm/XYFH1Ye9bokEYkgCvReJjPFz29uLSU+zvjSb5ZTdbTR65JEJEIo0Huh4twUnvhiCfsPNzDz6TIamlu9LklEIoACvZeaUJzNz24az+pdh/jGPI35IiIdU6D3YtPH9OPbV4zk1XX7+I8/vu91OSLSy+myxV7uKxcMZtfBOmYv3kpRTgqfP3eg1yWJSC+lQO/lzIzvXTWa8up67l+wjoL0RC4d3dfrskSkF1KXSwTwxRk/nzGBsYVZ3PnsKv625YDXJYlIL6RAjxCpifE8+aWzGZyXym1Pl7FqZ7XXJYlIL6NAjyBZKQn89iul5KcncutvlvP+Pg25KyIfU6BHmD4ZSTzzlXNI9vu45Yl32X6g1uuSRKSXUKBHoKKcFJ6ZWUprWxs3P/EOe2vqvS5JRHoBBXqEGtYnnae/fA419c3c8sQ7GiJARBTokeyswkx+/cUSyqvrufmJdzigUBeJaQr0CHfOkFzm3Ho226tqmTF7GRVHGrwuSUQ8okCPAucPy+PJL5Wy+1A9N81exv7DCnWRWKRAjxLnDsnlqS+Xsr+mgRsfX8qeQzpRKhJrFOhR5OxBOfx25jlUHW3ixtlLKa+u87okEelBCvQoM7E4m2dmnkNNXTM3Pr6MnVUKdZFYoUCPQuOKsnj2tnOpbWrhhseXsmn/Ea9LEpEeoECPUmMGZDJv1qdoc45/eGwpKzX2i0jUU6BHsTP6pvP8184jO8XPzb96h79uqvS6JBHpRiEFuplNN7MPzGyLmd13ivWuMzNnZiXhK1G6oignhd999TwG56Uy86nlLFyzx+uSRKSbdBjoZuYDHgUuB0YBM8xs1AnWSwfuAt4Jd5HSNfnpicz9x3OZUJzNXXNX8dul270uSUS6QSgt9FJgi3Nuq3OuCZgLXHOC9X4I/Cegu1p6oYwkP09/uZSLzyzguwvW89Brm3BOD54WiSahBPoAYFe76fLgvI+Y2USgyDn38qk2ZGazzKzMzMoqK9Wf29OS/D4eu2Ui108q5Gevb+auuatpaG71uiwRCZMunxQ1szjgp8C9Ha3rnJvtnCtxzpXk5+d3ddfSCfG+OH5y/Vj+efoZvPTeHm54fKmGChCJEqEE+m6gqN10YXDeMenAGOAvZrYdOBdYqBOjvZeZcfvUYcz+fAkfVhzl6l8sYc2uQ16XJSJdFEqgLweGm9lgM0sAbgIWHlvonKtxzuU55wY55wYBy4CrnXNl3VKxhM20UQU8f/t5+H1x3PD4Uhas3t3xh0Sk1+ow0J1zLcCdwCJgIzDfObfezB4ws6u7u0DpXmf2zWDBHeczriiLu+au5ieL3qe1TSdLRSKReXWlQ0lJiSsrUyO+t2hqaeP+het47t1dTB6ex8M3jic3LdHrskTkOGa2wjl3wi5t3SkqACTEx/Hvnz2L//g/Z/HOtoNc+fMllG0/6HVZInIaFOjyETPjptJi/nD7eST647hp9jKeeGurrlcXiRAKdPmE0f0zeenrF3DJyAIefHkjX31mBTX1zV6XJSIdUKDLCWUk+fnvWybynStH8vrGCq56RJc2ivR2CnQ5KTNj5uQhzPvHc2lpbeO6/36bX7yxWVfBiPRSCnTp0KSBObx61xQuP6sf/+9Pm7jx8aXsOqgnIYn0Ngp0CUlmip9HZkzg4RvH88G+I1z+s7d4YWW5TpiK9CIKdDkt104YwCt3TWZUvwzumb+GO59bxaG6Jq/LEhEU6NIJRTkpPDfrXL552RksWrePSx9azGsb9ntdlkjMU6BLp/jijDsuGsaLd5xPTmoCtz1dxt1zV1Fdq9a6iFcU6NIlYwZksvDOC7j7kuH873t7mfbQYv64bq/XZYnEJAW6dFlCfBx3XzKChXdeQEFGIl99ZiV3PruSqqONXpcmElMU6BI2o/pn8OId53PvtBEsWr+Pi3/6V+a+u5M2Xbcu0iMU6BJWfl8cX794OC//02RG9EnnvhfWct1jb7N+T43XpYlEPQW6dIsRBenM+8dz+a9/GMfOqjquemQJP3hpPUcaNCaMSHdRoEu3MTOum1TIG/dO5XPnFPPk29u5+L/+yoLVu9UNI9INFOjS7TJT/Dx47Vm8ePv5FGQkcdfc1XzmkSW8+X6F7jQVCSMFuvSYcUVZvHjH+Tx843iONrbwpSeX8w+PLeWdrVVelyYSFRTo0qN8cca1Ewbw53su5MFrx7DzYB03zl7GF+a8y9pynTgV6Qo9U1Q81dDcytNLt/PLv3zIobpmpo0q4O5LhjO6f6bXpYn0Sqd6pqgCXXqFww3N/GbJdp5YspUjDS1cNrqAuy8Zwch+GV6XJtKrKNAlYtTUNzNnyTbmLNnGkcYWLh/Tl7suGc6ZfRXsIqBAlwhUU9fMr5dsZc7ftnO0sYVLRxVw+0XDGF+U5XVpIp5SoEvEOlTXxJy/beept7dTU9/Mp4bk8rWpQ5k8PA8z87o8kR6nQJeId7Sxhbnv7uRXb21l/+FGRvfP4GtTh3L5mH744hTsEjtOFeghXbZoZtPN7AMz22Jm951g+T1mtsHM3jOz181sYFeLFmkvLTGemZOHsPifL+LH142lvqmVO59dxZQfv8kv3thMxZEGr0sU8VyHLXQz8wGbgGlAObAcmOGc29BunYuAd5xzdWb2NWCqc+7GU21XLXTpitY2x2sb9vPbZdv525Yq4uOMS0cXcPM5A/nUkFzi1GqXKHWqFnp8CJ8vBbY457YGNzYXuAb4KNCdc2+2W38ZcEvnyxXpmC/OmD6mL9PH9GVr5VGee3cnv19Rzitr9zE4L5UZpUVcP6mInNQEr0sV6TGhtNCvB6Y752YGpz8PnOOcu/Mk6/8C2Oece/AEy2YBswCKi4sn7dixo4vli3ysobmVP67bxzPLdlC2o5oEXxyXjenLjNIiPjUkVydRJSp0tYV+Oju6BSgBLjzRcufcbGA2BLpcwrlvkSS/j2snDODaCQPYtP8Iz727k+dXlPPSmj0MzkvlprOLuH5SIblpiV6XKtItQmmhfwr4vnPusuD0twCccz86br1LgEeAC51zFR3tWH3o0hMamlt5Ze1ennt3J8u3VxMfZ0w9I59rJwzgkpEFJPl9Xpcoclq6dNmimcUTOCl6MbCbwEnRzznn1rdbZwLwewJdM5tDKUqBLj1t8/4j/G5FOQtW72b/4UbSEuOZPqYvn50wgHOH5OryR4kIXb4O3cyuAB4GfMAc59y/mdkDQJlzbqGZ/Rk4Czj2uPedzrmrT7VNBbp4pbXN8c7WKv6wajevrtvH0cYWCjISmT66L5eN7kvp4BzifRqIVHon3VgkchINza28vrGCBat3s3hzJQ3NbWSl+LlkZAGXje7L5OF56paRXkWBLhKCuqYWFm86wKL1+3h9434ON7SQkuDjwhH5XDq6gE+fUUBmit/rMiXG9dhVLiKRLCUh/qNr25tb21i2tYo/rtvHaxv28+q6fcTHGecMyeHSUX2ZNqqA/lnJXpcs8nfUQhfpQFub473dNfxp/T7+tGE/WyqOAjCyXwZTRuQxZXg+JYOySYxX14x0P3W5iITRh5VHeW3Dfv7yQQUrdlTT3OpI9vs4Z0gOU4bnM2VEHkPz03Qjk3QLBbpIN6ltbGHZ1ioWb6pk8eYDbDtQC0C/zCQuGJbH5BH5nD80VzczSdgo0EV6yK6Ddby1+QBvba7kb1sOcLihBYDR/TO4YFgeEwdmM6E4iz7pSR5XKpFKgS7igdY2x3vlh1iy+QBvbTnAqp2B7hmAwuxkxhdlMaE4EPCj+2eoD15CokAX6QUamltZv6eGVTsPBf+q2VMTGMc9IT6OcYWZTBqYQ8nAbCYNzCZbI0XKCSjQRXqpfTUNrNpZzYod1ZTtqGb9npqPWvFD81MZV5TFmP6ZjBmQyaj+GaQl6krjWKdAF4kQDc2tvFdeQ9mOg6zcUc175TVUHGkEwAwG56YyekAmI/ulc0ZBOiMK0hmQlawHesQQ3VgkEiGS/D5KB+dQOjjno3kVhxtYv+cw63bXsG5PDSt3VPPSmj0fLU9J8DG8IJ0RfdIYUZDO8II0hhek0z8zSZdOxhgFukgv1ycjiT4ZSVx0Zp+P5tXUN7Ol4ggf7DvKpv1H2LT/CG9+UMnvVpR/tE5qgo9hfdIY1iedEQVpgaDvoxZ9NFOgi0SgzGQ/kwbmMGlgzt/NP1jbxJaKo2yuOMLm/YHXtzZX8vzKj4M+JcHH8D6BVvzwPmkMyU9jcF4qxTkpJMRrlMlIpkAXiSI5qQmf6LIBqKlrZnPFETbtD7ToN1ccYfGmSn7frkUfZ1CYncLgvFQG56UyMDeF4pzAX1FOikadjAAKdJEYkJnip2RQDiWDPhn0Ww8cZXtVLdsqa9lWVce2A0cp236Q2qbWv1u3T3oiA3NT6JuZTG5qAjmpCeSmJQTfJ5Kfnkj/rCRdT+8hBbpIDMtM8Qdvbsr+u/nOOQ7WNrHjYB27Dtaxs6qOnQfr2HGwjrXlh6g62sSRxpYTbrMgI5Gi7ECrvjA7maLsFPplJdE/K5n+mckkJyjwu4sCXUQ+wczITUskNy2RiceF/TGNLa1U1zZTVdvIwdomKg43Ul5dz67qwI/Au9sOsmB1PW3HXRmdneKnf1Yy/TKTyU9PIDc1sV1rP/A+O9VPVnICSf44XalzGhToItIpifE++mb66Jt58nFpmlvb2FfTwJ5D9eypqWfPocD7vTUNlFfXsXrXIQ7WNn4i9I9J8MWRmeInM9lPVrKfrBQ/WSmB7p6sFD/ZKQnBPz85qcfmJ8Ts82EV6CLSbfy+OIqCJ1VPpq3NUVPfTFVtE1VHA6396rpmauqbOVTfxOH6Zg4Fp3cfClyTf7C2icaWthNuzyxwFVBOSiD005L8pCb4SEmIJzUx+Jrg+/iHIiXh4x+L5ATSk+Ij9rJOBbqIeCouzshOTSA7NYFhfdJC/lx9UyvVdU3BH4DAj0B17cfTx14P1zezr6ae2sZW6ppaqG1qpekkPwYQuNonOyVQz7EfhZzUQNDH++Lw++Lwxxn++Dji44zE+DhSE+NJTYwnPfiamhhPelI8yQk+Uvy+HnvouAJdRCJScoKP5ITkTj0KsKmljcMNx1r+TRyqC7yvrmv66PXYj8LOg4GuoSMNLbS0tX001s7p8PuMZH/gXwcpCT4+d04xMycPOe3tdESBLiIxJyE+jry0RPI68eAR5xwtbY6WVkdTaxuNLa3UNbZytLGFo40t1AZfjza2UN/USn1TK3XNwdemFuqaWju131Ao0EVEToOZ4fcZfh8k4wP8kO51VQG6z1dEJEqEFOhmNt3MPjCzLWZ23wmWJ5rZvODyd8xsULgLFRGRU+sw0M3MBzwKXA6MAmaY2ajjVvsKUO2cGwY8BPxnuAsVEZFTC6WFXgpscc5tdc41AXOBa45b5xrgqeD73wMXm27vEhHpUaEE+gBgV7vp8uC8E67jnGsBaoDc4zdkZrPMrMzMyiorKztXsYiInFCPnhR1zs12zpU450ry8/N7ctciIlEvlEDfDRS1my4MzjvhOmYWD2QCVeEoUEREQhNKoC8HhpvZYDNLAG4CFh63zkLgi8H31wNvOK+ePi0iEqMslNw1s88MwOYAAAOBSURBVCuAhwEfMMc5929m9gBQ5pxbaGZJwG+BCcBB4Cbn3NYOtlkJ7Ohk3XnAgU5+NtLF6rHruGOLjvvkBjrnTthnHVKg9zZmVuacK/G6Di/E6rHruGOLjrtzdKeoiEiUUKCLiESJSA302V4X4KFYPXYdd2zRcXdCRPahi4jIJ0VqC11ERI6jQBcRiRIRF+gdDeUbLcxsjplVmNm6dvNyzOw1M9scfM32ssbuYGZFZvammW0ws/VmdldwflQfu5klmdm7ZrYmeNw/CM4fHBySektwiOoEr2vtDmbmM7NVZva/wemoP24z225ma81stZmVBed16XseUYEe4lC+0eJJYPpx8+4DXnfODQdeD05HmxbgXufcKOBc4I7gf+NoP/ZG4NPOuXHAeGC6mZ1LYCjqh4JDU1cTGKo6Gt0FbGw3HSvHfZFzbny7a8+79D2PqEAntKF8o4JzbjGBu27baz9M8VPAtT1aVA9wzu11zq0Mvj9C4H/yAUT5sbuAo8FJf/DPAZ8mMCQ1ROFxA5hZIXAl8ERw2oiB4z6JLn3PIy3QQxnKN5oVOOf2Bt/vAwq8LKa7BZ98NQF4hxg49mC3w2qgAngN+BA4FBySGqL3+/4w8M9AW3A6l9g4bgf8ycxWmNms4Lwufc/1kOgI5ZxzZha115yaWRrwPHC3c+5w++elROuxO+dagfFmlgX8ATjT45K6nZl9Bqhwzq0ws6le19PDLnDO7TazPsBrZvZ++4Wd+Z5HWgs9lKF8o9l+M+sHEHyt8LiebmFmfgJh/j/OuReCs2Pi2AGcc4eAN4FPAVnBIakhOr/v5wNXm9l2Al2onwZ+RvQfN8653cHXCgI/4KV08XseaYEeylC+0az9MMVfBBZ4WEu3CPaf/hrY6Jz7abtFUX3sZpYfbJljZsnANALnD94kMCQ1ROFxO+e+5ZwrdM4NIvD/8xvOuZuJ8uM2s1QzSz/2HrgUWEcXv+cRd6foiYby9bikbmFmzwFTCQynuR+4H3gRmA8UExh6+Abn3PEnTiOamV0AvAWs5eM+1X8l0I8etcduZmMJnATzEWhozXfOPWBmQwi0XHOAVcAtzrlG7yrtPsEul//rnPtMtB938Pj+EJyMB54NDkueSxe+5xEX6CIicmKR1uUiIiInoUAXEYkSCnQRkSihQBcRiRIKdBGRKKFAFxGJEgp0EZEo8f8Bq+iPTo/2D3gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "pd.DataFrame(history.history).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrDgRMYPGzzA"
      },
      "source": [
        "### 1) Defining inference models\n",
        "We create inference models which help in predicting translations.\n",
        "\n",
        "**Encoder inference model** : Takes the English sentence as input and outputs LSTM states ( `h` and `c` ).\n",
        "\n",
        "**Decoder inference model** : Takes in 2 inputs, one are the LSTM states ( Output of encoder model ), second are the Vietnamese input sequences ( ones not having the `<start>` tag ). It will output the translations of the English sentence which we fed to the encoder model and its state values.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uijAG4WUGTW9"
      },
      "outputs": [],
      "source": [
        "def make_inference_model():\n",
        "  encoder_model = models.Model(encoder_inputs, encoder_states)\n",
        "  \n",
        "  decoder_state_input_h = layers.Input(shape=(128, ))\n",
        "  decoder_state_input_c = layers.Input(shape=(128, ))\n",
        "\n",
        "  decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "  decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "      decoder_embedding, initial_state=decoder_state_inputs\n",
        "  )\n",
        "\n",
        "  decoder_states = [state_h, state_c]\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "  decoder_model = models.Model(\n",
        "      [decoder_inputs] + decoder_state_inputs,\n",
        "      [decoder_outputs] + decoder_states)\n",
        "  \n",
        "  return encoder_model, decoder_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVw4rrooQ_lV"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "### 2) Making some translations\n",
        "\n",
        "\n",
        "1.   First, we take a English sequence and predict the state values using `enc_model`.\n",
        "2.   We set the state values in the decoder's LSTM.\n",
        "3.   Then, we generate a sequence which contains the `<start>` element.\n",
        "4.   We input this sequence in the `dec_model`.\n",
        "5.   We replace the `<start>` element with the element which was predicted by the `dec_model` and update the state values.\n",
        "6.   We carry out the above steps iteratively till we hit the `<end>` tag or the maximum sequence length.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jFjWyD_qMxad"
      },
      "outputs": [],
      "source": [
        "def str_to_tokens(sentence: str):\n",
        "  sentence = sentence.lower()\n",
        "  words = underthesea.word_tokenize(sentence)\n",
        "  tokens_list = []\n",
        "\n",
        "  for word in words:\n",
        "      tokens_list.append(eng_word_dict[word]) \n",
        "  return preprocessing.sequence.pad_sequences([tokens_list], maxlen=max_input_length , padding='post')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "rK9uUpWaRv6B",
        "outputId": "6a5c8cbe-2d76-4035-d0b5-c1275a1acc4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter eng sentence : Run\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3541ff7dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            " chạy end\n",
            "Enter eng sentence : Do\n",
            " làm gì thì hãy end\n",
            "Enter eng sentence : Go\n",
            " đi end\n",
            "Enter eng sentence : Run after me\n",
            " chạy đi của bạn end\n",
            "Enter eng sentence : Run for your life\n",
            " cho thành phố của tên bạn end\n",
            "Enter eng sentence : Get out\n",
            " ra ngoài đi end\n",
            "Enter eng sentence : Get out of my car\n",
            " chạy xe của tôi đi end\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c93d2b304c4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mstates_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'Enter eng sentence : '\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mempty_target_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mempty_target_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvie_word_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "enc_model, dec_model = make_inference_model()\n",
        "\n",
        "for epoch in range(encoder_input_data.shape[0]):\n",
        "  states_values = enc_model.predict(str_to_tokens(input( 'Enter eng sentence : ' )))\n",
        "  empty_target_seq = np.zeros((1, 1))\n",
        "  empty_target_seq[0, 0] = vie_word_dict['start']\n",
        "  stop_condition = False\n",
        "  decoded_translation = \"\"\n",
        "\n",
        "  while not stop_condition:\n",
        "    dec_outputs, h, c = dec_model.predict([empty_target_seq] + states_values)\n",
        "    \n",
        "    sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "  \n",
        "    sampled_word = None\n",
        "    \n",
        "    for word, index in vie_word_dict.items():\n",
        "      if sampled_word_index == index:\n",
        "        decoded_translation += f' {word}'\n",
        "        sampled_word = word\n",
        "\n",
        "      if sampled_word == 'end' or len(decoded_translation.split()) > max_output_length:\n",
        "        stop_condition = True\n",
        "\n",
        "    empty_target_seq[0 , 0] = sampled_word_index\n",
        "    states_values = [h , c]\n",
        "\n",
        "  print(decoded_translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWkDYTUBlwug"
      },
      "source": [
        "DMô hình giải quyết được output không cố định số từ.\n",
        "\n",
        "Cũng không tốt lắm, cần dữ liệu nhiều hơn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aO8CXa7HVJfl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "machine_translation_18521283.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}