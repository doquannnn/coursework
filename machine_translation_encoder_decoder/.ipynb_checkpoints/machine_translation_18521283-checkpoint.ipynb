{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_K8sM32M9Ae7"
   },
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KW1TKXBb80IM"
   },
   "source": [
    "### 1) Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onpa6MgF0VpQ",
    "outputId": "37312c91-349c-4321-ad00-19bf41550381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: underthesea in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from underthesea) (0.9.7)\n",
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.2.2)\n",
      "Requirement already satisfied: torch<=1.5.1,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.5.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from underthesea) (4.41.1)\n",
      "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.2.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.13)\n",
      "Requirement already satisfied: transformers<=3.5.1,>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.5.1)\n",
      "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from underthesea) (2.23.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from underthesea) (0.22.2.post1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.2.5)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval->underthesea) (1.19.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch<=1.5.1,>=1.1.0->underthesea) (0.16.0)\n",
      "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.9.3)\n",
      "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.1.91)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (2019.12.20)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (3.12.4)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.0.45)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (3.0.12)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2021.5.30)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (1.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->underthesea) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<=3.5.1,>=3.5.0->underthesea) (2.4.7)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers<=3.5.1,>=3.5.0->underthesea) (57.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RzNh9zR1x12s"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
    "import pandas as pd\n",
    "import underthesea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83aRhJ8489j3"
   },
   "source": [
    "### 2) Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUcVxgCRxcZ7",
    "outputId": "f642436e-2a06-4813-b714-aeab89150bac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-30 15:13:49--  http://www.manythings.org/anki/vie-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.21.55.222, 172.67.173.198, 2606:4700:3031::6815:37de, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.21.55.222|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 298429 (291K) [application/zip]\n",
      "Saving to: ‘vie-eng.zip’\n",
      "\n",
      "vie-eng.zip         100%[===================>] 291.43K  1.20MB/s    in 0.2s    \n",
      "\n",
      "2021-06-30 15:13:50 (1.20 MB/s) - ‘vie-eng.zip’ saved [298429/298429]\n",
      "\n",
      "Archive:  vie-eng.zip\n",
      "replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: _about.txt              \n",
      "replace vie.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: vie.txt                 \n"
     ]
    }
   ],
   "source": [
    "!wget http://www.manythings.org/anki/vie-eng.zip -O vie-eng.zip\n",
    "!unzip vie-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "5hZjg0MKxmGL",
    "outputId": "ae3de347-9ad1-42d2-dd81-356eb3d9fe52"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>vie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Chạy !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Help!</td>\n",
       "      <td>Giúp tôi với !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go on.</td>\n",
       "      <td>Tiếp_tục đi .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello!</td>\n",
       "      <td>Chào bạn .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hurry!</td>\n",
       "      <td>Nhanh lên nào !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      eng              vie\n",
       "0    Run!           Chạy !\n",
       "1   Help!   Giúp tôi với !\n",
       "2  Go on.    Tiếp_tục đi .\n",
       "3  Hello!       Chào bạn .\n",
       "4  Hurry!  Nhanh lên nào !"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = pd.read_table('vie.txt', names=['eng', 'vie'])\n",
    "lines.reset_index(inplace=True)\n",
    "lines.rename( columns={ 'index' : 'eng' , 'eng' : 'vie' , 'vie' : 'c' }, inplace=True)\n",
    "lines.drop('c', axis=1, inplace=True)\n",
    "lines.vie = lines.vie.map(lambda x: underthesea.word_tokenize(x, format='text'))\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ass3El-R-SdF"
   },
   "source": [
    "### 3) Preparing input data for the Encoder ( `encoder_input_data` )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m8uOHQtt17rC",
    "outputId": "5ced84c7-4397-4f78-ac2a-d66d70473e0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English max length is 32\n",
      "Encoder input data shape -> (7547, 32)\n",
      "Number of English tokens = 3712\n"
     ]
    }
   ],
   "source": [
    "eng_lines = list(lines.eng)\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(eng_lines)\n",
    "tokenized_eng_lines = tokenizer.texts_to_sequences(eng_lines)\n",
    "\n",
    "max_input_length = len(max(tokenized_eng_lines, key=len))\n",
    "print( 'English max length is {}'.format(max_input_length))\n",
    "\n",
    "padded_eng_lines = preprocessing.sequence.pad_sequences(tokenized_eng_lines, maxlen=max_input_length, padding='post')\n",
    "encoder_input_data = np.array(padded_eng_lines)\n",
    "print( 'Encoder input data shape -> {}'.format(encoder_input_data.shape))\n",
    "\n",
    "eng_word_dict = tokenizer.word_index\n",
    "num_eng_tokens = len( eng_word_dict ) + 1\n",
    "print( 'Number of English tokens = {}'.format(num_eng_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OPGQG2U-Zz-"
   },
   "source": [
    "### 4) Preparing input data for the Decoder ( `decoder_input_data` )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXeXkn4W48iF",
    "outputId": "f1d2e05c-d312-4139-aae3-ef93ec24788a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viet Nam max length is 43\n",
      "Decoder input data shape -> (7547, 43)\n",
      "Number of Vietnamese tokens = 2364\n"
     ]
    }
   ],
   "source": [
    "vie_lines = list(lines.vie.map(lambda x: 'START ' + x + ' END'))\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(vie_lines)\n",
    "tokenized_vie_lines = tokenizer.texts_to_sequences(vie_lines)\n",
    "\n",
    "max_output_length = len(max(tokenized_vie_lines, key=len))\n",
    "print( 'Viet Nam max length is {}'.format(max_output_length))\n",
    "\n",
    "padded_vie_lines = preprocessing.sequence.pad_sequences(tokenized_vie_lines, maxlen=max_output_length, padding='post')\n",
    "decoder_input_data = np.array(padded_vie_lines)\n",
    "print( 'Decoder input data shape -> {}'.format(decoder_input_data.shape))\n",
    "\n",
    "vie_word_dict = tokenizer.word_index\n",
    "num_vie_tokens = len(vie_word_dict) + 1\n",
    "print( 'Number of Vietnamese tokens = {}'.format(num_vie_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOHumtnmBrK2"
   },
   "source": [
    "### 5) Preparing target data for the Decoder ( decoder_target_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jvVso7uCAbF"
   },
   "source": [
    "For example :\n",
    "\n",
    "```\n",
    " [ '<start>' , 'hello' , 'world' , '<end>' ]\n",
    "\n",
    "```\n",
    "\n",
    "wil become \n",
    "\n",
    "```\n",
    " [ 'hello' , 'world' , '<end>' ]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPw4Vubl5FRc",
    "outputId": "08e7743d-febb-4f56-c7e2-f09f0bec90ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder target data shape -> (7547, 43, 2364)\n"
     ]
    }
   ],
   "source": [
    "decoder_target_data = list(map(lambda token_seq: token_seq[1: ], tokenized_vie_lines))\n",
    "\n",
    "padded_vie_lines = preprocessing.sequence.pad_sequences(decoder_target_data , maxlen=max_output_length, padding='post' )\n",
    "onehot_vie_lines = utils.to_categorical(padded_vie_lines , num_vie_tokens)\n",
    "decoder_target_data = np.array(onehot_vie_lines)\n",
    "print( 'Decoder target data shape -> {}'.format( decoder_target_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqqdqpC5DQJf"
   },
   "source": [
    "## Defining and Training the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbN8fkdLDRTg"
   },
   "source": [
    "### 1) Defining the Encoder-Decoder model\n",
    "The model will have Embedding, LSTM and Dense layers. The basic configuration is as follows.\n",
    "\n",
    "\n",
    "*   2 Input Layers : One for `encoder_input_data` and another for `decoder_input_data`.\n",
    "*   Embedding layer : For converting token vectors to fix sized dense vectors. **( Note :  Don't forget the `mask_zero=True` argument here )**\n",
    "*   LSTM layer : Provide access to Long-Short Term cells.\n",
    "\n",
    "Working : \n",
    "\n",
    "1.   The `encoder_input_data` comes in the Embedding layer (  `encoder_embedding` ). \n",
    "2.   The output of the Embedding layer goes to the LSTM cell which produces 2 state vectors ( `h` and `c` which are `encoder_states` )\n",
    "3.   These states are set in the LSTM cell of the decoder.\n",
    "4.   The decoder_input_data comes in through the Embedding layer.\n",
    "5.   The Embeddings goes in LSTM cell ( which had the states ) to produce seqeunces.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eNeYeS2PFbEL"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vo4TmWY7ChL1",
    "outputId": "a23d5380-3bc5-4d4c-8617-5d89927f9182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 256)    950272      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 256)    605184      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 128), (None, 197120      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 128),  197120      embedding_3[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2364)   304956      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,254,652\n",
      "Trainable params: 2,254,652\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = layers.Input(shape=(None, ))\n",
    "encoder_embedding = layers.Embedding(num_eng_tokens, 256, mask_zero=True)(encoder_inputs)\n",
    "encoder_outputs, state_h, state_c = layers.LSTM(128, return_state=True)(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = layers.Input(shape=(None, ))\n",
    "decoder_embedding = layers.Embedding(num_vie_tokens, 256, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = layers.LSTM(128, return_state=True, return_sequences=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = layers.Dense(num_vie_tokens, activation='softmax')\n",
    "output = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLGjMpL8F2y_"
   },
   "source": [
    "### 2) Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5LPYsgXFCyBI",
    "outputId": "8f14cb8e-120e-4ad0-ad26-21d51295a7f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 1.1095\n",
      "Epoch 2/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 1.0094\n",
      "Epoch 3/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.9325\n",
      "Epoch 4/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.8703\n",
      "Epoch 5/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.8114\n",
      "Epoch 6/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.7544\n",
      "Epoch 7/50\n",
      "472/472 [==============================] - 15s 31ms/step - loss: 0.7017\n",
      "Epoch 8/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.6513\n",
      "Epoch 9/50\n",
      "472/472 [==============================] - 14s 31ms/step - loss: 0.6046\n",
      "Epoch 10/50\n",
      "472/472 [==============================] - 15s 31ms/step - loss: 0.5612\n",
      "Epoch 11/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.5206\n",
      "Epoch 12/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.4828\n",
      "Epoch 13/50\n",
      "472/472 [==============================] - 14s 31ms/step - loss: 0.4474\n",
      "Epoch 14/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.4150\n",
      "Epoch 15/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.3848\n",
      "Epoch 16/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.3571\n",
      "Epoch 17/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.3311\n",
      "Epoch 18/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.3071\n",
      "Epoch 19/50\n",
      "472/472 [==============================] - 14s 31ms/step - loss: 0.2856\n",
      "Epoch 20/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.2651\n",
      "Epoch 21/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.2470\n",
      "Epoch 22/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.2300\n",
      "Epoch 23/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.2134\n",
      "Epoch 24/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.1990\n",
      "Epoch 25/50\n",
      "472/472 [==============================] - 15s 31ms/step - loss: 0.1856\n",
      "Epoch 26/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.1732\n",
      "Epoch 27/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.1614\n",
      "Epoch 28/50\n",
      "472/472 [==============================] - 14s 31ms/step - loss: 0.1512\n",
      "Epoch 29/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.1407\n",
      "Epoch 30/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.1313\n",
      "Epoch 31/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.1245\n",
      "Epoch 32/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.1152\n",
      "Epoch 33/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.1087\n",
      "Epoch 34/50\n",
      "472/472 [==============================] - 14s 31ms/step - loss: 0.1016\n",
      "Epoch 35/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.0949\n",
      "Epoch 36/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.0897\n",
      "Epoch 37/50\n",
      "472/472 [==============================] - 14s 31ms/step - loss: 0.0841\n",
      "Epoch 38/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.0792\n",
      "Epoch 39/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.0749\n",
      "Epoch 40/50\n",
      "472/472 [==============================] - 15s 31ms/step - loss: 0.0711\n",
      "Epoch 41/50\n",
      "472/472 [==============================] - 14s 31ms/step - loss: 0.0675\n",
      "Epoch 42/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.0639\n",
      "Epoch 43/50\n",
      "472/472 [==============================] - 14s 31ms/step - loss: 0.0611\n",
      "Epoch 44/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.0579\n",
      "Epoch 45/50\n",
      "472/472 [==============================] - 14s 31ms/step - loss: 0.0543\n",
      "Epoch 46/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.0521\n",
      "Epoch 47/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.0501\n",
      "Epoch 48/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.0474\n",
      "Epoch 49/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.0458\n",
      "Epoch 50/50\n",
      "472/472 [==============================] - 14s 30ms/step - loss: 0.0440\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=16, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "_1KuJ34vIlyi",
    "outputId": "eee6a4f5-4cd5-46ed-892b-5db312ac3ba0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7feea0277ad0>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrDgRMYPGzzA"
   },
   "source": [
    "### 1) Defining inference models\n",
    "We create inference models which help in predicting translations.\n",
    "\n",
    "**Encoder inference model** : Takes the English sentence as input and outputs LSTM states ( `h` and `c` ).\n",
    "\n",
    "**Decoder inference model** : Takes in 2 inputs, one are the LSTM states ( Output of encoder model ), second are the Vietnamese input seqeunces ( ones not having the `<start>` tag ). It will output the translations of the English sentence which we fed to the encoder model and its state values.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uijAG4WUGTW9"
   },
   "outputs": [],
   "source": [
    "def make_inference_model():\n",
    "  encoder_model = models.Model(encoder_inputs, encoder_states)\n",
    "  \n",
    "  decoder_state_input_h = layers.Input(shape=(128, ))\n",
    "  decoder_state_input_c = layers.Input(shape=(128, ))\n",
    "\n",
    "  decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "  decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "      decoder_embedding, initial_state=decoder_state_inputs\n",
    "  )\n",
    "\n",
    "  decoder_states = [state_h, state_c]\n",
    "  decoder_outputs = decoder_dense(decoder_outputs)\n",
    "  decoder_model = models.Model(\n",
    "      [decoder_inputs] + decoder_state_inputs,\n",
    "      [decoder_outputs] + decoder_states)\n",
    "  \n",
    "  return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVw4rrooQ_lV"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "### 2) Making some translations\n",
    "\n",
    "\n",
    "1.   First, we take a English sequence and predict the state values using `enc_model`.\n",
    "2.   We set the state values in the decoder's LSTM.\n",
    "3.   Then, we generate a sequence which contains the `<start>` element.\n",
    "4.   We input this sequence in the `dec_model`.\n",
    "5.   We replace the `<start>` element with the element which was predicted by the `dec_model` and update the state values.\n",
    "6.   We carry out the above steps iteratively till we hit the `<end>` tag or the maximum sequence length.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jFjWyD_qMxad"
   },
   "outputs": [],
   "source": [
    "def str_to_tokens(sentence: str):\n",
    "  sentence = sentence.lower()\n",
    "  words = underthesea.word_tokenize(sentence)\n",
    "  tokens_list = []\n",
    "\n",
    "  for word in words:\n",
    "      tokens_list.append(eng_word_dict[word]) \n",
    "  return preprocessing.sequence.pad_sequences([tokens_list], maxlen=max_input_length , padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "id": "rK9uUpWaRv6B",
    "outputId": "ec8b1a00-8a58-4bb2-cb86-6d5236c55812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter eng sentence : I try\n",
      " tôi sẽ thử xem sao end\n",
      "Enter eng sentence : Are you thirsty\n",
      " bạn có khát nước không end\n",
      "Enter eng sentence : Are you hungry\n",
      " bạn có đói bụng không end\n",
      "Enter eng sentence : Are you crazy\n",
      " bạn đã ăn end\n",
      "Enter eng sentence : It's my favorite song\n",
      " đó là bài hát yêu thích của tôi end\n",
      "Enter eng sentence : Which year will you graduate\n",
      " bạn sẽ tốt nghiệp tuần sau end\n",
      "Enter eng sentence : I love traveling\n",
      " tôi thích vừa đi end\n",
      "Enter eng sentence : you are stupid a machine\n",
      " bạn bạn đã làm một bức thư của bạn end\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-53007f384c8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mstates_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'Enter eng sentence : '\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mempty_target_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mempty_target_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvie_word_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "enc_model, dec_model = make_inference_model()\n",
    "\n",
    "for epoch in range(encoder_input_data.shape[0]):\n",
    "  states_values = enc_model.predict(str_to_tokens(input( 'Enter eng sentence : ' )))\n",
    "  empty_target_seq = np.zeros((1, 1))\n",
    "  empty_target_seq[0, 0] = vie_word_dict['start']\n",
    "  stop_condition = False\n",
    "  decoded_translation = \"\"\n",
    "\n",
    "  while not stop_condition:\n",
    "    dec_outputs, h, c = dec_model.predict([empty_target_seq] + states_values)\n",
    "    sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
    "    sampled_word = None\n",
    "    \n",
    "    for word, index in vie_word_dict.items():\n",
    "      if sampled_word_index == index:\n",
    "        decoded_translation += f' {word}'\n",
    "        sampled_word = word\n",
    "\n",
    "      if sampled_word == 'end' or len(decoded_translation.split()) > max_output_length:\n",
    "        stop_condition = True\n",
    "\n",
    "    empty_target_seq[0 , 0] = sampled_word_index\n",
    "    states_values = [h , c]\n",
    "\n",
    "  print(decoded_translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWkDYTUBlwug"
   },
   "source": [
    "Mô hình giải quyết được output không cố định số từ.\n",
    "\n",
    "Cũng không tốt lắm, cần dữ liệu nhiều hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aO8CXa7HVJfl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "machine_translation_18521283.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
